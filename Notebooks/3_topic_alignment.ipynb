{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Topic Alignment using BERT + spaCy + Manual Annotations\n",
        "======================================================\n",
        "\n",
        "This script compares **Twitter API topics** with **TweetNLP topics** using:\n",
        "    - Sentence-BERT embeddings (semantic similarity)\n",
        "    - spaCy similarity scores (contextual overlap)\n",
        "    - Manual annotation fallback\n",
        "\n",
        "Decision rules:\n",
        "---------------\n",
        "1. If BERT == 1.0 OR spaCy == 1.0 â†’ Mark as \"BERT == 1\" and mark all other topics as \"High match already accepted\".\n",
        "2. Else, mark:\n",
        "      - BERT â‰¥ 0.5 â†’ \"BERT â‰¥ 0.5\"\n",
        "      - spaCy â‰¥ 0.65 â†’ \"spaCy â‰¥ 0.65\"\n",
        "3. If at least one threshold match exists, all lower matches â†’ \"High match already accepted\".\n",
        "4. Otherwise â†’ \"Manual Annotation Required\".\n",
        "\n",
        "Output:\n",
        "-------\n",
        "Saves results into a CSV file: **topic_alignment_final.csv**\n",
        "\"\"\"\n",
        "\n",
        "# -----------------------\n",
        "# INSTALLATION COMMANDS\n",
        "# -----------------------\n",
        "# Run these once before executing the script:\n",
        "# pip install pandas sentence-transformers spacy\n",
        "# python -m spacy download en_core_web_lg\n",
        "\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import spacy\n",
        "\n",
        "# -----------------------\n",
        "# CONFIGURATION\n",
        "# -----------------------\n",
        "\n",
        "# Thresholds\n",
        "BERT_THRESHOLD = 0.5\n",
        "SPACY_THRESHOLD = 0.65\n",
        "\n",
        "# Load Models\n",
        "print(\"ðŸ”„ Loading models...\")\n",
        "bert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "nlp_spacy = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "# Define TweetNLP topics\n",
        "tweetnlp_topics = [\n",
        "    'arts and culture', 'business and entrepreneurs', 'celebrity and pop culture',\n",
        "    'diaries and daily life', 'family', 'fashion and style', 'film tv and video',\n",
        "    'fitness and health', 'food and dining', 'gaming', 'learning and educational',\n",
        "    'music', 'news and social concern', 'other hobbies', 'relationships',\n",
        "    'science and technology', 'sports', 'travel and adventure', 'youth and student life'\n",
        "]\n",
        "\n",
        "# Example Twitter API topics (replace with your dataset)\n",
        "twitter_api_topics = [\n",
        "    \"american football\", \"artificial intelligence\", \"arts and culture\",\n",
        "    \"fashion and beauty\", \"designer fashion\", \"gaming\", \"technology\", \"MSFT\"\n",
        "]\n",
        "\n",
        "# -----------------------\n",
        "# PROCESSING LOGIC\n",
        "# -----------------------\n",
        "\n",
        "results = []\n",
        "\n",
        "for api_topic in twitter_api_topics:\n",
        "    scores = []\n",
        "\n",
        "    # Step 1: Compute similarity scores\n",
        "    for nlp_topic in tweetnlp_topics:\n",
        "        bert_score = util.cos_sim(\n",
        "            bert_model.encode(api_topic, convert_to_tensor=True),\n",
        "            bert_model.encode(nlp_topic, convert_to_tensor=True)\n",
        "        ).item()\n",
        "\n",
        "        spacy_score = nlp_spacy(api_topic).similarity(nlp_spacy(nlp_topic))\n",
        "        scores.append((nlp_topic, bert_score, spacy_score))\n",
        "\n",
        "    # Sort results by BERT first, then spaCy score\n",
        "    scores.sort(key=lambda x: (x[1], x[2]), reverse=True)\n",
        "\n",
        "    # Step 2: Check for perfect match\n",
        "    perfect_match = next(\n",
        "        ((t, b, s) for t, b, s in scores if b == 1.0 or s == 1.0),\n",
        "        None\n",
        "    )\n",
        "\n",
        "    if perfect_match:\n",
        "        # Mark the perfect match row\n",
        "        pm_topic, pm_bert, pm_spacy = perfect_match\n",
        "        results.append({\n",
        "            \"Twitter API Topic\": api_topic,\n",
        "            \"TweetNLP Topic\": pm_topic,\n",
        "            \"BERT Similarity\": round(pm_bert, 3),\n",
        "            \"spaCy Similarity\": round(pm_spacy, 3),\n",
        "            \"Decision\": \"BERT == 1\"\n",
        "        })\n",
        "\n",
        "        # Mark all others as high match already accepted\n",
        "        for t, b, s in scores:\n",
        "            if t != pm_topic:\n",
        "                results.append({\n",
        "                    \"Twitter API Topic\": api_topic,\n",
        "                    \"TweetNLP Topic\": t,\n",
        "                    \"BERT Similarity\": round(b, 3),\n",
        "                    \"spaCy Similarity\": round(s, 3),\n",
        "                    \"Decision\": \"High match already accepted\"\n",
        "                })\n",
        "        continue  # Skip threshold-based checks\n",
        "\n",
        "    # Step 3: Apply thresholds if no perfect match exists\n",
        "    accepted_matches = []\n",
        "    for t, b, s in scores:\n",
        "        if b >= BERT_THRESHOLD:\n",
        "            decision = \"BERT >= 0.5\"\n",
        "            accepted_matches.append(t)\n",
        "        elif s >= SPACY_THRESHOLD:\n",
        "            decision = \"spaCy >= 0.65\"\n",
        "            accepted_matches.append(t)\n",
        "        else:\n",
        "            decision = \"Manual Annotation Required\"\n",
        "\n",
        "        results.append({\n",
        "            \"Twitter API Topic\": api_topic,\n",
        "            \"TweetNLP Topic\": t,\n",
        "            \"BERT Similarity\": round(b, 3),\n",
        "            \"spaCy Similarity\": round(s, 3),\n",
        "            \"Decision\": decision\n",
        "        })\n",
        "\n",
        "    # Step 4: If any threshold matches exist â†’ mark all other lower-score rows\n",
        "    if accepted_matches:\n",
        "        for row in results:\n",
        "            if (row[\"Twitter API Topic\"] == api_topic and\n",
        "                row[\"TweetNLP Topic\"] not in accepted_matches and\n",
        "                row[\"Decision\"] == \"Manual Annotation Required\"):\n",
        "                row[\"Decision\"] = \"High match already accepted\"\n",
        "\n",
        "# -----------------------\n",
        "# SAVE RESULTS\n",
        "# -----------------------\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "df = df.sort_values(by=[\"Twitter API Topic\", \"BERT Similarity\"], ascending=[True, False])\n",
        "df.to_csv(\"topic_alignment_final.csv\", index=False)\n",
        "\n",
        "print(\"\\n Results saved to topic_alignment_final.csv\")\n"
      ],
      "metadata": {
        "id": "BgHz_DHXEb62"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}