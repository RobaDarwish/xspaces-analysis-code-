{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==============================================\n",
        "# Network Construction + Network Measures\n",
        "# ==============================================\n",
        "\n",
        "# ---- 1. Import libraries ----\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# ==============================================\n",
        "# PART 1: Network Construction\n",
        "# ==============================================\n",
        "\n",
        "# ---- 2. Upload CSV files ----\n",
        "print(\"Upload 'sample_users.csv' and 'sample_relationships.csv'\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# ---- 3. Load datasets ----\n",
        "user_df = pd.read_csv(io.BytesIO(uploaded['sample_users.csv']))\n",
        "relationships_df = pd.read_csv(io.BytesIO(uploaded['sample_relationships.csv']))\n",
        "\n",
        "# ---- 4. Build the graph ----\n",
        "G = nx.Graph()\n",
        "G.add_nodes_from(user_df['userId'])\n",
        "\n",
        "# Add edges with or without weights\n",
        "edges = relationships_df[['user1_id', 'user2_id']].values.tolist()\n",
        "if 'weight' in relationships_df.columns:\n",
        "    weights = relationships_df['weight'].values.tolist()\n",
        "    for (u, v), w in zip(edges, weights):\n",
        "        G.add_edge(u, v, weight=w)\n",
        "else:\n",
        "    G.add_edges_from(edges)\n",
        "\n",
        "# ---- 5. Basic graph summary ----\n",
        "print(f\"Graph successfully created!\")\n",
        "print(f\"Nodes: {G.number_of_nodes()} | Edges: {G.number_of_edges()}\")\n",
        "\n",
        "# ==============================================\n",
        "# PART 2: Network Measures\n",
        "# ==============================================\n",
        "\n",
        "print(\"\\nCalculating network measures...\\n\")\n",
        "\n",
        "# ---- 1. Number of connected components ----\n",
        "num_components = nx.number_connected_components(G)\n",
        "print(f\"Number of connected components: {num_components}\")\n",
        "\n",
        "# Get the largest connected component for path-based metrics\n",
        "largest_cc = max(nx.connected_components(G), key=len)\n",
        "largest_subgraph = G.subgraph(largest_cc)\n",
        "\n",
        "# ---- 2. Average degree ----\n",
        "avg_degree = sum(dict(G.degree()).values()) / G.number_of_nodes()\n",
        "print(f\"Average degree: {avg_degree:.2f}\")\n",
        "\n",
        "# ---- 3. Degree statistics ----\n",
        "degrees = [deg for _, deg in G.degree()]\n",
        "mean_degree = np.mean(degrees)\n",
        "median_degree = np.median(degrees)\n",
        "std_dev_degree = np.std(degrees)\n",
        "print(f\"Mean degree: {mean_degree:.2f}\")\n",
        "print(f\"Median degree: {median_degree:.2f}\")\n",
        "print(f\"Std. deviation of degree: {std_dev_degree:.2f}\")\n",
        "\n",
        "# ---- 4. Clustering coefficients ----\n",
        "clustering_coeffs = list(nx.clustering(G).values())\n",
        "mean_clustering = np.mean(clustering_coeffs)\n",
        "median_clustering = np.median(clustering_coeffs)\n",
        "std_clustering = np.std(clustering_coeffs)\n",
        "print(f\"Mean clustering coefficient: {mean_clustering:.4f}\")\n",
        "print(f\"Median clustering coefficient: {median_clustering:.4f}\")\n",
        "print(f\"Std. deviation of clustering: {std_clustering:.4f}\")\n",
        "\n",
        "# ---- 5. Transitivity ----\n",
        "transitivity = nx.transitivity(G)\n",
        "print(f\"Transitivity: {transitivity:.4f}\")\n",
        "\n",
        "# ---- 6. Density ----\n",
        "density = nx.density(G)\n",
        "print(f\"Graph density: {density:.4f}\")\n",
        "\n",
        "# ---- 7. Shortest path lengths ----\n",
        "if nx.is_connected(G):\n",
        "    path_lengths = dict(nx.all_pairs_shortest_path_length(G))\n",
        "else:\n",
        "    path_lengths = dict(nx.all_pairs_shortest_path_length(largest_subgraph))\n",
        "\n",
        "# Extract all shortest path values into a flat list\n",
        "all_paths = []\n",
        "for source in path_lengths:\n",
        "    all_paths.extend(path_lengths[source].values())\n",
        "\n",
        "mean_path = np.mean(all_paths)\n",
        "median_path = np.median(all_paths)\n",
        "std_path = np.std(all_paths)\n",
        "print(f\"Mean shortest path length: {mean_path:.4f}\")\n",
        "print(f\"Median shortest path length: {median_path:.4f}\")\n",
        "print(f\"Std. deviation of shortest paths: {std_path:.4f}\")\n",
        "\n",
        "print(\"\\n Network measures calculated successfully!\")\n"
      ],
      "metadata": {
        "id": "MO_eBM_-l_Qv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}